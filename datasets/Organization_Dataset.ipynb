{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7JQDV-rSybRe",
        "s7JcB_Vc6gmo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Processing for organization dataset\n",
        "Authors: Sanjana and Rachel\n",
        "\n",
        "Needed files: \n",
        "\n",
        "*   interest_areas.txt\n",
        "*   interest_categories.txt\n",
        "*   org_dataset.csv\n",
        "*   encoded_org_dataset.csv\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XEDmZx3FHibT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Import libraries"
      ],
      "metadata": {
        "id": "TFS-LuUZH-Yi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU0P0yjLxz51"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "import copy\n",
        "import re\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process age columns into single majority age group designation\n",
        "Author: Sanjana"
      ],
      "metadata": {
        "id": "iCuZeDOmxTBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/org_dataset.csv')"
      ],
      "metadata": {
        "id": "ikpycNVbyFlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "dc517022-528c-44b6-ffa7-1f2e325b9c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5c8513f3e723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/org_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/org_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"df type: {type(df)}\")\n",
        "print(f\"df shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "xwhxuUBHzCA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "hPykXjpwzF9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep copy selected columns "
      ],
      "metadata": {
        "id": "4e4G3yRIaZ5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "organization = copy.deepcopy(df['Organization/ City Agency/ Division Name'])\n",
        "total_vol = copy.deepcopy(df['Total Vounteers'])\n",
        "youth_vol = copy.deepcopy(df['Youth volunteers'])\n",
        "adult_vol = copy.deepcopy(df['Adult Volunteers'])\n",
        "older_vol = copy.deepcopy(df['Older adult Volunteers'])"
      ],
      "metadata": {
        "id": "02Cb_476z2E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean up volunteer age data "
      ],
      "metadata": {
        "id": "75uU-NWfadRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(total_vol)):\n",
        "  total_vol[i] = total_vol[i].replace(',', '')\n",
        "  youth_vol[i] = youth_vol[i].replace(',','')\n",
        "  youth_vol[i] = youth_vol[i].replace('-','0')\n",
        "  adult_vol[i] = adult_vol[i].replace(',','')\n",
        "  adult_vol[i] = adult_vol[i].replace('-','0')\n",
        "  older_vol[i] = older_vol[i].replace(',','')\n",
        "  older_vol[i] = older_vol[i].replace('-','0')"
      ],
      "metadata": {
        "id": "K7dPjpsRGFGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lists"
      ],
      "metadata": {
        "id": "qlDofgrdbrfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_vol = [float(i) for i in total_vol]\n",
        "youth_vol = [float(i) for i in youth_vol]\n",
        "adult_vol = [float(i) for i in adult_vol]\n",
        "older_vol = [float(i) for i in older_vol]\n",
        "\n",
        "organizationZero =[]"
      ],
      "metadata": {
        "id": "AR9s-nkJGYVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete all zero entries from lists\n",
        "\n",
        "Keep track of totall zero entries"
      ],
      "metadata": {
        "id": "r214HSjwb2kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_Zeros = 0\n",
        "\n",
        "for i in range(len(total_vol)-1, -1, -1):     # iterate backwards\n",
        "  if youth_vol[i] == 0 and adult_vol[i] == 0 and older_vol[i] == 0: \n",
        "\n",
        "    total_Zeros +=1\n",
        "    organizationZero.append(organization[i])\n",
        "    \n",
        "\n",
        "    del(total_vol[i])\n",
        "    del(youth_vol[i])\n",
        "    del(adult_vol[i])\n",
        "    del(older_vol[i])\n",
        "    del(organization[i])"
      ],
      "metadata": {
        "id": "VOE1yvBzHWn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct given age data"
      ],
      "metadata": {
        "id": "60mZ8-MAcRJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictIn = {\"Total volunteers\" : total_vol, \"Youth volunteers\": youth_vol, \"Adult volunteers\" : adult_vol, \"Older volunteers\" : older_vol}"
      ],
      "metadata": {
        "id": "0QHnBAEUGhjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(dictIn)\n",
        "df2_vols = df2.loc[:,df2.columns != 'Total volunteers']"
      ],
      "metadata": {
        "id": "Nd_g_uhDG4UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get max volunteers in age groups for each organization "
      ],
      "metadata": {
        "id": "TfDF7m4RcdZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxList = []\n",
        "maxList = re.findall('[A-Z][^A-Z]*',df2_vols.idxmax(axis=1).sum())"
      ],
      "metadata": {
        "id": "f6qRJW5DPJJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in maxList:\n",
        "  if (i == 'Youth volunteers'):\n",
        "    maxList[maxList.index(i)] = 0\n",
        "  \n",
        "  elif(i == 'Adult volunteers'):\n",
        "   maxList[maxList.index(i)] = 1\n",
        "\n",
        "  elif(i == 'Older volunteers'):\n",
        "    maxList[maxList.index(i)] = 2\n"
      ],
      "metadata": {
        "id": "3Wz7NuuPVaJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Age data for Zero entries with respect to age demographics in NYC"
      ],
      "metadata": {
        "id": "-7FUyn3ncqVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import choice\n",
        "\n",
        "ageList = [0,1,2]\n",
        "\n",
        "generatedAgeArray = choice(ageList,total_Zeros, p=[0.10,0.78,0.12]) "
      ],
      "metadata": {
        "id": "yjtgPX3cajXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join given and generated data  "
      ],
      "metadata": {
        "id": "k5x20hWwc1ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in generatedAgeArray:\n",
        "  maxList.append(generatedAgeArray[i])\n"
      ],
      "metadata": {
        "id": "5H1DOQJFTydk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "organizationList = []\n",
        "for i in organization:\n",
        "  organizationList.append(str(i))\n",
        "\n",
        "for i in organizationZero:\n",
        "  organizationList.append(i)"
      ],
      "metadata": {
        "id": "PRTBe39WT-Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictAge = {\"Organization/ City Agency/ Division Name\" : organizationList, \"Most volunteers in age group\" : maxList}"
      ],
      "metadata": {
        "id": "RSMXyxJqWVcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_finalAge = pd.DataFrame(dictAge)"
      ],
      "metadata": {
        "id": "VLi2Ou3wWsHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final age dataset "
      ],
      "metadata": {
        "id": "JNIurbXFdBtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_finalAge"
      ],
      "metadata": {
        "id": "9K-lSAqGW1KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process interests into categories\n",
        "Author: Rachel"
      ],
      "metadata": {
        "id": "UYn3uwpCxZ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open files\n",
        "areas_file = open('/content/interest_areas.txt', 'r')   # list of all interests w/ category designations\n",
        "cat_file = open('/content/interest_categories.txt', 'r')    # list of all categories w/ numbers"
      ],
      "metadata": {
        "id": "0oMnJoOaxcvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Process interest areas list"
      ],
      "metadata": {
        "id": "7JQDV-rSybRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for areas file\n",
        "lines = areas_file.read()\n",
        "interests_list = lines.split('\\n')"
      ],
      "metadata": {
        "id": "iJjLsniJXcQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(interests_list)):\n",
        "  interests_list[i] = interests_list[i].split('=')\n",
        "  interests_list[i][1] = interests_list[i][1].split(',')\n",
        "\n",
        "interests_list"
      ],
      "metadata": {
        "id": "wwEa-G-9eqAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list with all interests for each category\n",
        "categories_list = []\n",
        "\n",
        "for i in range(10):\n",
        "  temp_list = []\n",
        "  for j in range(len(interests_list)):\n",
        "    if str(i+1) in interests_list[j][1]:\n",
        "      temp_list.append(interests_list[j][0])\n",
        "  categories_list.append(temp_list)\n",
        "\n",
        "categories_list"
      ],
      "metadata": {
        "id": "60ClBHydl_ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Process category file"
      ],
      "metadata": {
        "id": "kagAMLw7ynAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = cat_file.read()\n",
        "short_cat_list = lines.split('\\n')\n",
        "\n",
        "for i in range(len(short_cat_list)):\n",
        "  short_cat_list[i] = short_cat_list[i].split('*')\n",
        "\n",
        "short_cat_list"
      ],
      "metadata": {
        "id": "sJGt1oCPlkd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Modify dataset"
      ],
      "metadata": {
        "id": "yEKmPexlyr66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "org_df = pd.read_csv('/content/org_dataset.csv')"
      ],
      "metadata": {
        "id": "wQsQr7Fv7mEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_areas = org_df['Interest Areas']\n",
        "cat_col = []\n",
        "\n",
        "for i in range(len(interest_areas)):\n",
        "  temp_list = []\n",
        "  interests = ''\n",
        "  for entry in categories_list:   # go through each entry in the interests listed by category\n",
        "    for item in entry:    # go through every interest area in each category\n",
        "      if item in repr(interest_areas[i]):\n",
        "        temp_list.append(short_cat_list[categories_list.index(entry)][1])\n",
        "\n",
        "  # convert to dictionary and back to remove duplicates     \n",
        "  temp_dict = dict.fromkeys(temp_list)\n",
        "  temp_list = temp_dict.keys()\n",
        "  \n",
        "  # put into string separated by commas\n",
        "  for interest in temp_list:\n",
        "    interests = interests + interest + ';'\n",
        "  cat_col.append(interests.rstrip(';'))\n",
        "\n",
        "# list type\n",
        "cat_col"
      ],
      "metadata": {
        "id": "qFTiQM13gKFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "org_df['Interest Categories'] = cat_col\n",
        "org_df.head()"
      ],
      "metadata": {
        "id": "jkeRKo7M_iTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "areas_file.close()\n",
        "cat_file.close()"
      ],
      "metadata": {
        "id": "gq1L2iSWYOYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining dataframes for final organization dataset\n",
        "Authors: Sanjana and Rachel"
      ],
      "metadata": {
        "id": "ocXe2k6PxPId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge dataframes"
      ],
      "metadata": {
        "id": "5YJNgj6m6dcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.merge(org_df,df_finalAge, on=\"Organization/ City Agency/ Division Name\")\n",
        "\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "rwIw0GurxQ6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.columns"
      ],
      "metadata": {
        "id": "w0vREyguz1dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.drop(['Street Address/Mailing Address', 'City', 'State', 'Postcode',\n",
        "       'Year Surveyed', 'Total Vounteers', 'Youth volunteers',\n",
        "       'Adult Volunteers', 'Older adult Volunteers', 'Interest Areas', 'Special Populations Served', 'Boroughs  Served',\n",
        "       'Latitude', 'Longitude', 'Community Board',\n",
        "       'Council District', 'Census Tract', 'BIN', 'BBL', 'NTA'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "WBy_-lWWz8S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: column 'Organization Type\" could be useful for displaying in front-end"
      ],
      "metadata": {
        "id": "lL7jEVAd1Q0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = df4.loc[:,df4.columns != 'Organization Type']"
      ],
      "metadata": {
        "id": "upUdm0De0tiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Handling missing values"
      ],
      "metadata": {
        "id": "P_V2o5cIXHTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.isna().sum()"
      ],
      "metadata": {
        "id": "XxDezmKTXac3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "borough = copy.deepcopy(final_df['Borough'])"
      ],
      "metadata": {
        "id": "Idp3cweWXcXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boroughs of missing values with respect to locations of organizations "
      ],
      "metadata": {
        "id": "a1RV8UGswxB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generatedBoroughList = [ \"MANHATTAN\", \"BROOKLYN\", \"QUEENS\", \"MANHATTAN\", \"BRONX\", \"BROOKLYN\", \"BROOKLYN\", \"BRONX\", \"QUEENS\", \"BROOKLYN\", \"QUEENS\", \"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"BRONX\", \"QUEENS\", \"QUEENS\", \"BROOKLYN\", \"MANHATTAN\",\"BRONX\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"MANHATTAN\",\"BRONX\", \"QUEENS\", \"MANHATTAN\", \"BROOKLYN\", \"MANHATTAN\",\"MANHATTAN\", \"QUEENS\", \"QUEENS\",\"QUEENS\",\"QUEENS\",\"BRONX\",\"MANHATTAN\",\"MANHATTAN\", \"MANHATTAN\",\"QUEENS\", \"MANHATTAN\"]\n",
        "                        "
      ],
      "metadata": {
        "id": "sccpOI0BXeH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naNIndex = []\n",
        "for i in range(len(borough)):\n",
        "  if not (isinstance(borough[i],str)):\n",
        "    naNIndex.append(i)\n"
      ],
      "metadata": {
        "id": "bdwUaAfdhf4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert researched boroughs into borough list"
      ],
      "metadata": {
        "id": "p3xXE5p4w8r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in naNIndex:\n",
        "  if count < 44:\n",
        "    borough[i] = generatedBoroughList[count]\n",
        "    count +=1"
      ],
      "metadata": {
        "id": "YDuwPh3SkJXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boroughList = []\n",
        "for i in range(len(borough)):\n",
        "    boroughList.append(borough[i])"
      ],
      "metadata": {
        "id": "T0e4FHm9p1Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove previous Borough column with missing values"
      ],
      "metadata": {
        "id": "2yQ-fd7PxFBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.drop('Borough', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NLgzHe7vnF-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert new Borough column "
      ],
      "metadata": {
        "id": "uXQedIjMxLRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.insert(1,'Borough',boroughList)"
      ],
      "metadata": {
        "id": "0wkjz8TmoAvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check"
      ],
      "metadata": {
        "id": "bXk2WnpCxOy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.isna().sum()"
      ],
      "metadata": {
        "id": "W8NIG5K2oXMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final pre encoded organization dataset"
      ],
      "metadata": {
        "id": "ZKFKqFVAxSkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "R5jr5G3kssje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save to CSV file"
      ],
      "metadata": {
        "id": "s7JcB_Vc6gmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df.to_csv(\"/content/Preencoding_final_dataframe.csv\")"
      ],
      "metadata": {
        "id": "WfSl_rTD2FIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df = pd.read_csv(\"/content/Preencoding_final_dataframe.csv\")"
      ],
      "metadata": {
        "id": "cZKkEsZw4vBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####One-hot Encoding"
      ],
      "metadata": {
        "id": "yKooqJTK7SXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding boroughs"
      ],
      "metadata": {
        "id": "cv54MS4Y9x_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hotBoroughs = pd.get_dummies(final_df['Borough'])"
      ],
      "metadata": {
        "id": "g8gq1v7a7Xjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.join(one_hotBoroughs)"
      ],
      "metadata": {
        "id": "61uZOK7-7dIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.loc[:,final_df.columns != 'Unnamed']"
      ],
      "metadata": {
        "id": "2rpNORmEuraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding interests"
      ],
      "metadata": {
        "id": "yJQ0W0sv91aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interests = final_df['Interest Categories']\n",
        "\n",
        "zero_column = []\n",
        "for i in range(len(interests)):\n",
        "  zero_column.append(0)\n",
        "\n",
        "one_hot_list = []\n",
        "for i in range(10):\n",
        "  one_hot_list.append(copy.deepcopy(zero_column))\n",
        "\n",
        "categories = []\n",
        "for item in short_cat_list:\n",
        "  categories.append(item[1])\n"
      ],
      "metadata": {
        "id": "syaMQXDy8EQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(interests)):\n",
        "  interests_list = interests[i].split(';')\n",
        "  for item in interests_list:\n",
        "    if item != '':\n",
        "      one_hot_list[categories.index(item)][i] = 1\n",
        "\n",
        "interests_dict = {'Health services': one_hot_list[0],\n",
        "                  'Social services': one_hot_list[1],\n",
        "                  'Advocacy and Justice': one_hot_list[2],\n",
        "                  'Food and Agriculture': one_hot_list[3],\n",
        "                  'Education': one_hot_list[4],\n",
        "                  'Environment and Climate change': one_hot_list[5],\n",
        "                  'Recreation and Leisure': one_hot_list[6],\n",
        "                  'Technology and Innovation': one_hot_list[7],\n",
        "                  'Outreach and Advertising': one_hot_list[8],\n",
        "                  'Child services': one_hot_list[9]}"
      ],
      "metadata": {
        "id": "-Y_om4CyA2L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interests_df = pd.DataFrame.from_dict(interests_dict) "
      ],
      "metadata": {
        "id": "OrLBhqozDhF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interests_df['Organization/ City Agency/ Division Name'] = final_df['Organization/ City Agency/ Division Name']"
      ],
      "metadata": {
        "id": "j-wwm6C2DjsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = pd.merge(interests_df, final_df, on='Organization/ City Agency/ Division Name')"
      ],
      "metadata": {
        "id": "ycPNQwVDErzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df"
      ],
      "metadata": {
        "id": "svAjs5iXvddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save encoded dataframe to CSV file"
      ],
      "metadata": {
        "id": "dF2q2ZLQFJbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#encoded_df.to_csv('/content/encoded_org_final_dataset.csv')"
      ],
      "metadata": {
        "id": "vhq5zvN2E-f-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}